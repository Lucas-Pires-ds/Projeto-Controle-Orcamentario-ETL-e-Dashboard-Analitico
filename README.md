# ğŸ“Š Projeto de Controle OrÃ§amentÃ¡rio â€” Pipeline ETL e Analytics
## VisÃ£o Geral

Este projeto simula um **pipeline completo de dados para controle orÃ§amentÃ¡rio**, cobrindo desde a ingestÃ£o de dados brutos atÃ© a preparaÃ§Ã£o de um **modelo analÃ­tico pronto para consumo em Power BI**.

O foco principal nÃ£o Ã© apenas gerar dashboards, mas **demonstrar pensamento de engenharia analÃ­tica**, com atenÃ§Ã£o especial Ã  **qualidade dos dados**, **rastreabilidade**, **modelagem dimensional** e **integridade referencial** â€” problemas reais encontrados em ambientes corporativos.

O projeto foi desenvolvido com **SQL Server**, **Python** e **Power BI**, adotando boas prÃ¡ticas de arquitetura e ETL utilizadas no mercado.

## ğŸ¯ Problema de NegÃ³cio

Empresas que trabalham com orÃ§amento frequentemente enfrentam desafios como:

* Dados financeiros vindos de mÃºltiplas fontes e com baixa padronizaÃ§Ã£o

* Falta de controle de qualidade antes da anÃ¡lise

* Dificuldade em garantir consistÃªncia entre categorias, centros de custo e campanhas

Este projeto resolve esses problemas ao estruturar um pipeline que:

* Centraliza os dados

* Sanea inconsistÃªncias ainda na camada de dados

* Entrega dimensÃµes confiÃ¡veis para anÃ¡lises financeiras e orÃ§amentÃ¡rias

## ğŸ—ï¸ Arquitetura de Dados

![Arquitetura do Pipeline de Dados](docs_e_imagens/diagrama_pipeline_de_dados.png)

Foi adotado o padrÃ£o Medallion Architecture, separando claramente as responsabilidades de cada camada:

### ğŸ¥‰ Camada Bronze (stg_)

* IngestÃ£o de dados brutos via **Python (Pandas) + Bulk Insert**

* Todas as colunas armazenadas como VARCHAR(MAX) ou VARCHAR(200)

* Objetivo: **garantir que a carga nunca falhe por incompatibilidade de tipos**

> **Nota:** Os caminhos utilizados nos comandos `BULK INSERT` sÃ£o parametrizÃ¡veis e devem ser ajustados conforme o ambiente local de execuÃ§Ã£o.


A decisÃ£o de manter dados nÃ£o tipados nesta camada permite que o saneamento ocorra de forma controlada no SQL Server.

### ğŸ¥ˆ Camada Silver (dim_)

* PersistÃªncia fÃ­sica dos dados transformados e tipados

* AplicaÃ§Ã£o de **PRIMARY KEY** e **FOREIGN KEY**

* PreparaÃ§Ã£o de um **modelo dimensional (Star Schema)**

As tabelas desta camada sÃ£o a base confiÃ¡vel para o consumo analÃ­tico.

### ğŸ” TransformaÃ§Ãµes via Views (vw_)

* As transformaÃ§Ãµes entre Bronze e Silver sÃ£o feitas via **Views**

* Permite testar e ajustar regras de limpeza **sem reprocessar a carga fÃ­sica**

* Facilita auditoria, manutenÃ§Ã£o e rastreabilidade

## âœ… Framework de Qualidade de Dados

Antes da carga definitiva na camada Silver, foi implementado um conjunto de queries de diagnÃ³stico, atuando como um framework de Data Quality.

### Principais validaÃ§Ãµes

* **Auditoria de EspaÃ§os:** detecÃ§Ã£o de espaÃ§os extras com LEN(col) > LEN(TRIM(col))

* **Sanidade de IDs:** identificaÃ§Ã£o de valores como 101.0 importados como string

* **ValidaÃ§Ã£o de DomÃ­nio:** meses fora do intervalo vÃ¡lido (1â€“12)

* **Unicidade:** verificaÃ§Ã£o de chaves primÃ¡rias duplicadas (GROUP BY + HAVING COUNT(*) > 1)

Essas validaÃ§Ãµes permitem identificar problemas antes da persistÃªncia fÃ­sica, evitando erros silenciosos no modelo analÃ­tico.

## âš™ï¸ DecisÃµes TÃ©cnicas de ETL
### ConversÃ£o de Tipagem Complexa

Para tratar IDs numÃ©ricos importados como strings decimais (ex: "101.0"), foi utilizada a conversÃ£o aninhada:

CAST(CAST(id_categoria AS FLOAT) AS INT)


Essa abordagem evita erros comuns do SQL Server ao tentar converter diretamente strings com ponto decimal para inteiros.

### PadronizaÃ§Ã£o SemÃ¢ntica de Strings

Foi desenvolvida uma lÃ³gica de InitCap personalizada, com foco na estÃ©tica do dashboard sem comprometer o negÃ³cio:

* Primeira letra maiÃºscula, demais minÃºsculas

* PreservaÃ§Ã£o de siglas em caixa alta (ex: **RH**, **TI**)

* Tratamento correto de delimitadores (ex: "Limpeza/ConservaÃ§Ã£o")

### Integridade e Saneamento de Dados

* Registros com **IDs nulos na origem** foram identificados como causa raiz de duplicidades

* Esses registros foram descartados ainda na View (WHERE id IS NOT NULL)

* ValidaÃ§Ã£o cruzada garantiu que **toda categoria possua um Centro de Custo vÃ¡lido** antes da carga na Silver

## ğŸ§© Modelo Dimensional (Silver)

O modelo foi construÃ­do seguindo o padrÃ£o Star Schema, com foco em performance e clareza analÃ­tica.

### DimensÃµes implementadas

* **dim_centro_custo** â€” centros responsÃ¡veis pelo orÃ§amento

* **dim_categoria** â€” natureza das despesas (com FK para centro de custo)

* **dim_camp_marketing** â€” campanhas e referÃªncia temporal

* **dim_fornecedores** â€” fornecedores envolvidos nos lanÃ§amentos

## ğŸ“„ Tabela Fato â€” fact_lancamentos (Silver Layer)

A tabela fact_lancamentos representa os lanÃ§amentos financeiros efetivos e passou por um processo rigoroso de diagnÃ³stico e saneamento antes da carga definitiva.

### DiagnÃ³stico de Qualidade de Dados (PrÃ©-Carga)

Durante o Data Profiling na tabela stg_lancamentos, foram identificados os seguintes pontos crÃ­ticos:

- **Integridade Temporal**
  - 27 registros com data nula (~0,6% do montante financeiro)

- **Integridade Referencial**
  - 65 registros (~1,3%) com Centros de Custo inexistentes na dimensÃ£o

- **Anomalias de Sinal**
  - LanÃ§amentos com valores negativos sem correlaÃ§Ã£o com estorno ou cancelamento

- **InconsistÃªncia SemÃ¢ntica**
  - Status de pagamento duplicados por variaÃ§Ã£o de case e gÃªnero
  - Exemplos: "Paga", "PAGO", "pago", "Pending"

---

### DecisÃµes de Engenharia e Regras de NegÃ³cio

Para garantir confiabilidade analÃ­tica sem perda relevante de informaÃ§Ã£o, foram aplicadas as seguintes estratÃ©gias:

- **Descarte EstratÃ©gico**
  - Registros sem data foram removidos devido ao alto risco analÃ­tico e baixo impacto financeiro (~0,6%)

- **Membro Coringa (Default Member)**
  - CriaÃ§Ã£o do registro `-1 (NÃƒO IDENTIFICADO)` na `dim_centro_custo`
  - Permite preservar ~1,3% da massa financeira sem violar integridade referencial

- **RedundÃ¢ncia Defensiva de Valores**
  - `valor`: valor absoluto tratado com `ABS()`, protegido por `CHECK CONSTRAINT (> 0)`
  - `valor_original`: preservaÃ§Ã£o do dado bruto para auditoria e rastreabilidade

- **NormalizaÃ§Ã£o SemÃ¢ntica**
  - PadronizaÃ§Ã£o dos status de pagamento para apenas:
    - `Pago`
    - `Aberto`
  - Implementada via `CASE WHEN` com `UPPER()` e `TRIM()`

---

### ImplementaÃ§Ã£o TÃ©cnica

- TransformaÃ§Ãµes centralizadas na `vw_lancamentos`
- ConversÃ£o de tipos:
  - `INT` para IDs
  - `DATETIME` para datas
  - `DECIMAL(16,2)` para valores
- Tratamento de IDs com resÃ­duos decimais:
  - `CAST(CAST(col AS FLOAT) AS INT)`

### Status Final da fact_lancamentos

- **Primary Key:** definida sobre `id_lancamento`
- **Foreign Keys:** garantem vÃ­nculo com dimensÃµes vÃ¡lidas ou membro coringa
- **Qualidade:** 100% dos registros respeitam regras de negÃ³cio e integridade referencial

## ğŸ“¦ Auditoria Final da Carga

ApÃ³s o carregamento da Silver:

* Carga realizada via INSERT INTO ... SELECT FROM vw_

* ValidaÃ§Ã£o de volumetria comparando tabelas atravÃ©s de UNION ALL

* DiferenÃ§as de registros foram analisadas e justificadas por filtros de qualidade

**Resultado:** dimensÃµes prontas para consumo analÃ­tico, sem inconsistÃªncias estruturais.

## ğŸ“Š Camada Gold e AnÃ¡lises

A camada Gold Ã© destinada ao consumo final no Power BI, utilizando:

* Tabelas fato de LanÃ§amentos e OrÃ§amento

* DimensÃµes saneadas como filtros

* MÃ©tricas financeiras e orÃ§amentÃ¡rias

*(Dashboards em evoluÃ§Ã£o)*

## ğŸ› ï¸ Stack Utilizada

* **SQL Server** â€” ETL, modelagem dimensional e integridade

* **Python (Pandas)** â€” ingestÃ£o e geraÃ§Ã£o de dados sintÃ©ticos

* **Power BI** â€” visualizaÃ§Ã£o e anÃ¡lise

* **Git / GitHub** â€” versionamento e documentaÃ§Ã£o

## ğŸ“Œ Objetivo do Projeto

Este projeto tem como objetivo consolidar e demonstrar competÃªncias tÃ©cnicas em anÃ¡lise de dados, BI e engenharia analÃ­tica, por meio da construÃ§Ã£o de um pipeline completo de dados financeiros.

A iniciativa reflete um processo contÃ­nuo de desenvolvimento tÃ©cnico e aprofundamento em boas prÃ¡ticas de mercado, demonstrando:

- Pensamento arquitetural  
- Rigor em qualidade de dados  
- Capacidade de transformar dados brutos em ativos analÃ­ticos confiÃ¡veis  


## ğŸ“ PrÃ³ximos Passos

* Implementar o pipeline ETL da tabela fato fact_orcamentos

* Evoluir a camada Gold

* Publicar dashboards finais

* Adicionar diagrama visual da arquitetura

ğŸ“¬ Fique Ã  vontade para explorar o repositÃ³rio e entrar em contato para feedbacks ou sugestÃµes.

